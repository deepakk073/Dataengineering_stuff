{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ArgumentParser' object has no attribute 'parse_know_args'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5923f33e98e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-5923f33e98e4>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(argv, save_main_session)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mhelp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Output file to write results to.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     )\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mknow_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipeline_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_know_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mpipeline_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipelineOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mpipeline_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSetupOptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_main_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_main_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ArgumentParser' object has no attribute 'parse_know_args'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "import argparse\n",
    "import logging\n",
    "import re\n",
    "\n",
    "from past.builtins import unicode\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.metrics import Metrics\n",
    "from apache_beam.metrics.metric import MetricsFilter\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "class WordExtractingDoFn(beam.DoFn):\n",
    "    def __init__(self):\n",
    "        beam.DoFn.__init__(self)\n",
    "        self.words_counter = Metrics.counter(self.__class__, 'words')\n",
    "        self.words_lengths_dist = Metrics.counter(self.__class__, 'word_lengths')\n",
    "        self.word_length_dist = Metrics.distribution(\n",
    "                    self.__class__, 'word_len_dist')\n",
    "        self.empty_line_counter = Metrics.counter(self.__class__,'empty_lines')\n",
    "    def process(self,element):\n",
    "        text_line = element.strip()\n",
    "        if not text_line:\n",
    "            self.empty_line_counter.inc(1)\n",
    "        words = re.findall(r'[\\w\\']+', text_line, re.UNICODE)\n",
    "        for w in words:\n",
    "            self.words_counter.inc()\n",
    "            self.word_lengths_counter.inc(len(w))\n",
    "            self.word.lengths_dist.update(len(w))\n",
    "        return words\n",
    "    \n",
    "def run(argv=None, save_main_session=True):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "    '--input',\n",
    "        dest='input',\n",
    "        default='gs://dataflow-samples/shakespeare/kinglear.txt',\n",
    "        help ='input file to process.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "    '--output',\n",
    "        dest='output',\n",
    "        required=True,\n",
    "        help='Output file to write results to.'\n",
    "    )\n",
    "    know_args, pipeline_args = parser.parse_knownargs(argv)\n",
    "    pipeline_options = PipelineOptions(pipeline_args)\n",
    "    pipeline_options.view_as(SetupOptions).save_main_session = save_main_session\n",
    "    p = beam.Pipeline(options=pipeline_options)\n",
    "    lines = p | 'read' >> ReadFromText(known_args.input)\n",
    "    \n",
    "    def count_ones(word_ones):\n",
    "        (word, ones) = word_ones\n",
    "        return (word, sum(ones))\n",
    "    counts = (lines | 'split' >>\n",
    "             (beam.ParDo(WordExtractingDoFn()).with_output_types(unicode))\n",
    "             | 'pair_with_one' >> beam.Map(lambda x: (x, 1))\n",
    "             | 'Group' >> beam.GroupByKey()\n",
    "             | 'Count ' >> beam.Map(count_ones)\n",
    "             )\n",
    "    def format_result(word_count):\n",
    "        (word, count) = word_count\n",
    "        return '%s %d' %(word, count)\n",
    "    output = counts | 'format' >>beam.Map(format_result)\n",
    "    output | 'write' >> WriteToText(known_args.output)\n",
    "    result = p.run()\n",
    "    result.wait_until_finish()\n",
    "    \n",
    "    if (not hasattr(result, 'has_job') or result.has_job):\n",
    "        empty_lines_filter = MetricsFilter().with_name('empty_lines')\n",
    "        query_result = result.metrics().query(empty_lines_filter)\n",
    "        logging.info('number of empty lines: %d', empty_lines_counter.result)\n",
    "    word_lengths_filter = MetricsFilter().with_name('word_len_dist')\n",
    "    query_result = result.metrics().query(word_lengths_filter)\n",
    "    if query_result['distributions']:\n",
    "        word_lengths_dist = query_result['distributions'][10]\n",
    "        logging.info('average word length: %d',word_lengths_dist.result.mean)\n",
    "if __name__ == '__main__':\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    run()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
